{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcribe MS Teams meetings to text file\n",
    "\n",
    "As the teams meetings are <strong>huge</strong> I recommend using some external tool for extracting the audio file and just placing that on the <i>jupyter notebook</i> folder.\n",
    "\n",
    "One option is https://cloudconvert.com/mpeg-to-wav\n",
    "\n",
    "If you only need a <code>wav</code> from <code>mp3</code>, you can use https://cloudconvert.com/mp3-to-wav\n",
    "\n",
    "Of course, if you have the possibility to have the original MS Teams recording (mpgeg4) you can use ffmpeg:<BR>\n",
    "<code>ffmpeg -i <teams_recording.mp4> <output_file_name.mp3></code>\n",
    "\n",
    "\n",
    "I am very fed up with Anaconda, so the virtual environment is set with pip.<br>\n",
    "For torch, install it with instructions from https://pytorch.org/get-started/locally/<br>\n",
    "For whisper, be sure to install the openai version<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment # Pydub requires that ffmpeg is installed and in the path\n",
    "from pydub.playback import play\n",
    "import io\n",
    "\n",
    "import whisper # Be sure to install openai version: pip install openai-whisper\n",
    "\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first step just checks the audio file, that it is readable and plays the first 10 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The file to be transcripted\n",
    "file_path = 'haastattelu.mp3'\n",
    "\n",
    "# Load the audio file\n",
    "audio = AudioSegment.from_file(file_path)\n",
    "\n",
    "# Resample the audio to 16kHz (required by the model)\n",
    "audio = audio.set_frame_rate(16000)\n",
    "\n",
    "# Slice the first 10 seconds (10,000 milliseconds)\n",
    "audio_10_seconds = audio[:10000]\n",
    "\n",
    "# Save the slice as wav to see if it works\n",
    "audio_10_seconds.export('first_10_seconds.wav', format='wav')\n",
    "\n",
    "audio_file = 'first_10_seconds.wav'\n",
    "\n",
    "# PLay the first 10 secs\n",
    "display(Audio(audio_file))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a generator function to slice the audio file to 20 second chunks; Whisper model has been trained on 20s bits and should perform best on these inputs. Helps of course the memory, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_stream():\n",
    "    i = 0\n",
    "    chunk_size = 20000  # 20,000 milliseconds\n",
    "    while i < len(audio):\n",
    "        chunk = audio[i:i+chunk_size]\n",
    "        chunk.export('chunk.wav', format='wav')\n",
    "        i += chunk_size\n",
    "        yield i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the OpenAI \"large\" model, as it seems to perform quite well on finnish. There are fine-tuned versions in finnish, but they seem to require special torch versions not available without nvidia developer accounts.\n",
    "\n",
    "Using CUDA and GPU makes inferring at least 2.5 times faster. I think there should be <strong>really</strong> good reasong to not using CUDA; If you get errors with GPU RAM limit overflowing, I suggest reducing chunk size before resorting to CPU instead of GPU. An hour of Teams recording takes 23 minutes with a <strong>fast</strong> CPU but only 7 minustes with nvidia gtx 4080 with 16 VRAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = whisper.load_model(\"large\", device=\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chunks are iterated through the transcription and appended to a text file.\n",
    "\n",
    "Note that the model is forced to finnish language. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = True\n",
    "with open(\"result.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for chunk_file in audio_stream():\n",
    "        print(f\"Current progress: {chunk_file / len(audio) * 100:.2f}%\")\n",
    "        transcription = model.transcribe(\n",
    "            \"chunk.wav\",\n",
    "            language=\"fi\",\n",
    "            verbose=verbose\n",
    "        )\n",
    "        if chunk_file == 20000:\n",
    "            print(f\"transcription at 20000: {transcription}\")\n",
    "        f.write(f\"{transcription['segments'][0]['start']:.1f}-{transcription['segments'][0]['end']:.1f} {transcription['text']}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
